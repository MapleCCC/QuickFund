#!/usr/bin/env python3

import atexit
import locale
import os
import re
import shelve
import shutil
import sys
import threading
import traceback
from datetime import date, datetime, time, timedelta
from functools import lru_cache
from itertools import filterfalse
from pathlib import Path
from typing import Dict, Iterable, List, Tuple

import attr
import click
import colorama
import semver
import xlsxwriter

from .__version__ import __version__
from .config import REPO_NAME, REPO_OWNER
from .fetcher import fetch_estimate, fetch_net_value
from .github_utils import get_latest_release_version
from .lru import LRU
from .schema import FundInfo
from .tqdm_enhanced import tenumerate, thread_map, tmap, tqdm, trange
from .utils import Logger, bright_blue, print_traceback_digest

# GUI feature of tqdm is experimental. And our application is too fast for the plot to render.
# from tqdm.gui import tqdm, trange


if locale.getdefaultlocale()[0] == "zh_CN":
    PERSISTENT_CACHE_DB_DIRECTORY = ".ç¼“å­˜"
else:
    PERSISTENT_CACHE_DB_DIRECTORY = ".cache"
# Instead of using full filename, we use basename, because shelve requires so.
PERSISTENT_CACHE_DB_FILE_BASENAME = "cache"
PERSISTENT_CACHE_DB_RECORD_MAX_NUM = 2000

ERR_LOG_FILE = "é”™è¯¯æ—¥å¿—.txt"

logger = Logger()


def write_to_xlsx(fund_infos: List[FundInfo], xlsx_filename: str) -> None:
    """
    Structuralize a list of fund infos to an Excel document.

    Input: a list of fund infos, and an Excel filename.
    """

    try:
        # TODO profile to see whether and how much setting constant_memory improves
        # performance.
        with xlsxwriter.Workbook(xlsx_filename, {"constant_memory": True}) as workbook:

            logger.log("æ–°å»º Excel æ–‡æ¡£......")
            worksheet = workbook.add_worksheet()

            # Widen column
            for i, field in enumerate(attr.fields(FundInfo)):
                width = field.metadata.get("width")
                # FIXME Despite the xlsxwriter doc saying that set_column(i, i, None) doesn't
                # change the column width, some simple tests show that it does. The source
                # code of xlsxwriter is too complex that I can't figure out where the
                # bug originates.
                worksheet.set_column(i, i, width)

            # Write header
            logger.log("å†™å…¥æ–‡æ¡£å¤´......")
            for i, field in enumerate(attr.fields(FundInfo)):
                header_format = workbook.add_format(
                    {"bold": True, "align": "center", "valign": "top", "border": 1}
                )
                worksheet.write_string(0, i, field.name, header_format)

            # Write body
            logger.log("å†™å…¥æ–‡æ¡£ä½“......")
            for row, info in tenumerate(fund_infos, start=1, unit="è¡Œ", desc="å†™å…¥åŸºé‡‘ä¿¡æ¯"):
                for col, field in enumerate(attr.fields(FundInfo)):
                    # Judging from source code of xlsxwriter, add_format(None) is
                    # equivalent to default format.
                    cell_format = workbook.add_format(field.metadata.get("format"))
                    worksheet.write(row, col, info[col], cell_format)

            logger.log("Flush åˆ°ç¡¬ç›˜......")

    except Exception as exc:
        raise RuntimeError(f"è·å–åŸºé‡‘ä¿¡æ¯å¹¶å†™å…¥ Excel æ–‡æ¡£çš„æ—¶å€™å‘ç”Ÿé”™è¯¯") from exc


def check_args(in_filenames: Iterable[str], out_filename: str) -> None:
    """
    Check validness of command line arguments
    """

    # Check in_filenames
    for f in in_filenames:
        if not os.path.exists(f):
            raise FileNotFoundError(f"æ–‡ä»¶ {f} ä¸å­˜åœ¨")

    # Check out_filename
    if os.path.isdir(out_filename):
        raise RuntimeError(f'åŒåæ–‡ä»¶å¤¹å·²å­˜åœ¨ï¼Œæ— æ³•æ–°å»ºæ–‡ä»¶ "{out_filename}"')

    if os.path.isfile(out_filename):
        # If out_filename already exists, make a backup.

        if locale.getdefaultlocale()[0] == "zh_CN":
            backup_filename = "[å¤‡ä»½] " + out_filename
        else:
            backup_filename = out_filename + ".bak"

        try:
            shutil.move(out_filename, backup_filename)
        except PermissionError:
            raise RuntimeError(
                f"å¤‡ä»½ Excel æ–‡æ¡£æ—¶å‘ç”Ÿæƒé™é”™è¯¯ï¼Œæœ‰å¯èƒ½æ˜¯ Excel æ–‡æ¡£å·²ç»è¢«å…¶ä»–ç¨‹åºå ç”¨ï¼Œ"
                f'æœ‰å¯èƒ½æ˜¯ "{out_filename}" å·²ç»è¢« Excel æ‰“å¼€ï¼Œ'
                "è¯·å…³é—­æ–‡ä»¶ä¹‹åé‡è¯•"
            ) from None
        logger.log(f'"{out_filename}" åŒåæ–‡ä»¶å·²å­˜åœ¨ï¼Œå¤‡ä»½è‡³ "{backup_filename}"')


def check_update() -> None:
    """
    Check if update to the program is available.
    """

    logger.log("è·å–æœ€æ–°åˆ†å‘ç‰ˆæœ¬å·......")
    # TODO Handle the case when the latest release's tag name is not semantic
    # version.
    # TODO Handle the case when the latest release's tag name is semantic version but
    # with additional suffix, like rc (release candidate), build, etc.
    try:
        latest_version = get_latest_release_version(REPO_OWNER, REPO_NAME)
    except:
        logger.log("è·å–æœ€æ–°åˆ†å‘ç‰ˆæœ¬å·çš„æ—¶å€™å‘ç”Ÿé”™è¯¯ï¼Œæš‚æ—¶è·³è¿‡ã€‚å¯ä»¥é€šè¿‡ --update å‘½ä»¤æ¥æ‰‹åŠ¨è§¦å‘æ›´æ–°æ£€æŸ¥")
        return

    if semver.compare(latest_version, __version__) > 0:
        logger.log(f"æ£€æµ‹åˆ°æ›´æ–°ç‰ˆæœ¬ {latest_version}ï¼Œè¯·æ‰‹åŠ¨æ›´æ–°")
        sys.exit()
    else:
        logger.log("å½“å‰å·²æ˜¯æœ€æ–°ç‰ˆæœ¬")


def net_value_date_is_latest(net_value_date: date) -> bool:
    """
    Check if the net value date is latest.

    Take advantage of the knowledge that fund info stays the same
    within 0:00 to 20:00.

    WARNING: it's true that most of time the market is not opened
    in weekends. But we can't use this knowledge in our logic. Because
    sometimes holiday policy will make this irregular. We'd better
    fall back to use the most robust way to check.
    """

    now_time = datetime.now().time()
    today = date.today()
    yesterday = today - timedelta(days=1)

    if time.min <= now_time < time(20):
        return net_value_date == yesterday
    else:
        return net_value_date == today


def estimate_datetime_is_latest(estimate_datetime: datetime) -> bool:
    """
    Check if the estimte datetime is latest.

    Take advantage of the knowledge that estimate info stays the same
    within 15:00 to next day 15:00.

    WARNING: it's true that most of time the market is not opened
    in weekends. But we can't use this knowledge in our logic. Because
    sometimes holiday policy will make this irregular. We'd better
    fall back to use the most robust way to check.
    """

    open_market_time = time(9, 30)
    close_market_time = time(15)
    now_time = datetime.now().time()
    today = date.today()
    yesterday = today - timedelta(days=1)
    today_close_market_datetime = datetime.combine(today, close_market_time)
    yesterday_close_market_datetime = datetime.combine(yesterday, close_market_time)

    if open_market_time <= now_time <= close_market_time:
        return False
    elif time.min <= now_time < open_market_time:
        return estimate_datetime == yesterday_close_market_datetime
    elif close_market_time < now_time <= time.max:
        return estimate_datetime == today_close_market_datetime
    else:
        raise RuntimeError("Unreachable")


def get_fund_infos(fund_codes: List[str]) -> List[FundInfo]:
    """
    Input: a list of fund codes
    Output: a list of fund infos corresponding to the fund code
    """

    if not os.path.isdir(PERSISTENT_CACHE_DB_DIRECTORY):
        os.makedirs(PERSISTENT_CACHE_DB_DIRECTORY)

    shelf_path = os.path.join(
        PERSISTENT_CACHE_DB_DIRECTORY, PERSISTENT_CACHE_DB_FILE_BASENAME
    )

    with shelve.open(shelf_path) as fund_info_cache_db:
        # Check protocol version
        cache_db_protocol_version = fund_info_cache_db.get("protocol_version")
        if cache_db_protocol_version is None or cache_db_protocol_version < __version__:
            logger.log("ç¼“å­˜æ•°æ®åº“çš„åè®®ç‰ˆæœ¬è¿‡ä½æˆ–ä¿¡æ¯ç¼ºå¤±ï¼Œæ›´æ–°åˆ°æ–°ç‰ˆæœ¬ï¼Œå¹¶æ¸…ç©ºæ—§åè®®å­˜å‚¨......")
            fund_info_cache_db.clear()

        fund_info_cache_db["protocol_version"] = __version__

        # Create variable `new_records` to keep track of the fund infos that get refreshed.
        new_records_access_lock = threading.Lock()
        new_records: Dict[str, FundInfo] = {}

        def add_to_new_records(fund_code: str, fund_info: FundInfo) -> None:
            # TIPS: Uncomment following line to profile lock congestion.
            # print(renewed_variable_access_lock.locked())
            new_records_access_lock.acquire()
            new_records[fund_code] = fund_info
            new_records_access_lock.release()

        @lru_cache(maxsize=None)
        def get_fund_info(fund_code: str) -> FundInfo:
            """
            Input: a fund code
            Output: fund info related to the fund code
            """

            need_renew = False
            fund_info: FundInfo = fund_info_cache_db.get(fund_code, FundInfo())

            net_value_date = fund_info.å‡€å€¼æ—¥æœŸ
            if net_value_date is None or not net_value_date_is_latest(net_value_date):
                need_renew = True
                data = fetch_net_value(fund_code)
                fund_info.åŸºé‡‘ä»£ç  = data.åŸºé‡‘ä»£ç 
                fund_info.å‡€å€¼æ—¥æœŸ = data.å‡€å€¼æ—¥æœŸ
                fund_info.å•ä½å‡€å€¼ = data.å•ä½å‡€å€¼
                fund_info.æ—¥å¢é•¿ç‡ = data.æ—¥å¢é•¿ç‡
                fund_info.åˆ†çº¢é€é… = data.åˆ†çº¢é€é…
                fund_info.ä¸Šä¸€å¤©å‡€å€¼ = data.ä¸Šä¸€å¤©å‡€å€¼
                fund_info.ä¸Šä¸€å¤©å‡€å€¼æ—¥æœŸ = data.ä¸Šä¸€å¤©å‡€å€¼æ—¥æœŸ

            estimate_datetime = fund_info.ä¼°ç®—æ—¥æœŸ
            if estimate_datetime is None or not estimate_datetime_is_latest(
                estimate_datetime
            ):
                need_renew = True
                data = fetch_estimate(fund_code)
                fund_info.åŸºé‡‘ä»£ç  = data.åŸºé‡‘ä»£ç 
                fund_info.åŸºé‡‘åç§° = data.åŸºé‡‘åç§°
                fund_info.ä¼°ç®—æ—¥æœŸ = data.ä¼°ç®—æ—¥æœŸ
                fund_info.å®æ—¶ä¼°å€¼ = data.å®æ—¶ä¼°å€¼
                fund_info.ä¼°ç®—å¢é•¿ç‡ = data.ä¼°ç®—å¢é•¿ç‡

            if need_renew:
                add_to_new_records(fund_code, fund_info)

            return fund_info

        # FIXME experiment to find a suitable number as threshold between sync and
        # async code
        if len(fund_codes) < 3:
            fund_infos = list(tmap(get_fund_info, fund_codes, unit="ä¸ª", desc="è·å–åŸºé‡‘ä¿¡æ¯"))
        else:
            fund_infos = list(
                thread_map(get_fund_info, fund_codes, unit="ä¸ª", desc="è·å–åŸºé‡‘ä¿¡æ¯")
            )

        logger.log("å°†åŸºé‡‘ç›¸å…³ä¿¡æ¯å†™å…¥æ•°æ®åº“ï¼Œç•™å¤‡ä¸‹æ¬¡ä½¿ç”¨ï¼ŒåŠ é€Ÿä¸‹æ¬¡æŸ¥è¯¢......")
        fund_info_cache_db.update(new_records)

        logger.log("æ›´æ–°ç¼“å­˜ LRU ä¿¡æ¯......")

        # TODO remove out-dated cache entries

        # Instead of directly in-place updating the "lru_record" entry in
        # fund_info_cache_db, we copy it to a new variable and update the
        # new variable and then copy back. This is because directly in-place
        # updating shelve dict entry requires opening shelve with the `writeback`
        # parameter set to True, which could lead to increased memory cost
        # and IO cost, hence slowing down the program.

        lru = fund_info_cache_db.get("lru_record", LRU())
        lru.batch_update(fund_codes)

        if lru.size > PERSISTENT_CACHE_DB_RECORD_MAX_NUM:
            logger.log("æ£€æµ‹åˆ°ç¼“å­˜è¾ƒå¤§ï¼Œæ¸…ç†ç¼“å­˜......")
            to_evict_num = PERSISTENT_CACHE_DB_RECORD_MAX_NUM - len(lru)
            for _ in trange(to_evict_num, unit="æ¡", desc="æ¸…ç†ç¼“å­˜"):
                del fund_info_cache_db[lru.evict()]

        fund_info_cache_db["lru_record"] = lru

        return fund_infos


def validate_fund_code(s: str) -> bool:
    """ Check if a string represents a valid fund code """
    return bool(re.fullmatch(r"[0-9]{6}", s))


@click.command(
    name="fund-info-fetcher",
    help="A script to fetch various fund information from https://fund.eastmoney.com, and structuralize into Excel document",
    epilog="Input file format: one fund code per line.",
    no_args_is_help=True,  # type: ignore
)
@click.argument(
    "fund_codes_or_files",
    nargs=-1,
    metavar="<fund codes or files containing fund codes>",
)
@click.option(
    "-o",
    "--output",
    default="åŸºé‡‘ä¿¡æ¯.xlsx",
    show_default=True,
    help="The output file path.",
)
@click.option("--disable-update-check", is_flag=True, help="Disable update check.")
# @click.option("--disable-cache", is_flag=True)
# @click.option("--versbose", is_flag=True)
# TODO: @click.option("--update")
@click.version_option(version=__version__)
def main(
    fund_codes_or_files: Tuple[str], output: str, disable_update_check: bool
) -> None:
    """ Command line entry function """

    colorama.init()

    @atexit.register
    def pause_wait_enter() -> None:
        if locale.getdefaultlocale()[0] == "zh_CN":
            # localization for Simplified Chinese
            msg = "æŒ‰å›è½¦é”®ä»¥é€€å‡º"
        else:
            # default to English
            msg = "Press ENTER to exit"
        # WARNING: colorama doesn't seem to be compatible with the builtin input()
        # function under some console environment. The workaround here is to transform
        # from `input("xxx")` to `print("xxx"); input()`.
        print(bright_blue(msg), end="")
        input()

    try:
        # TODO Remove update check logic after switching architecture to
        # server/client model
        if not disable_update_check:
            print("æ£€æŸ¥æ›´æ–°......")
            check_update()

        if not fund_codes_or_files:
            # FIXME
            print("Usage: fund-info-fetch <list of fund codes>")
            sys.exit()

        in_filenames = filterfalse(validate_fund_code, fund_codes_or_files)
        out_filename = output

        logger.log("æ£€æŸ¥å‚æ•°......")
        check_args(in_filenames, out_filename)

        logger.log("è·å–åŸºé‡‘ä»£ç åˆ—è¡¨......")
        fund_codes = []
        for x in fund_codes_or_files:
            if validate_fund_code(x):
                # if x is fund code
                fund_codes.append(x)
            else:
                # if x is filename
                lines = Path(x).read_text(encoding="utf-8").splitlines()
                cleaned_lines = map(str.strip, lines)
                fund_codes.extend(filter(validate_fund_code, cleaned_lines))

        if not fund_codes:
            logger.log("æ²¡æœ‰å‘ç°åŸºé‡‘ä»£ç ")
            sys.exit()

        logger.log("è·å–åŸºé‡‘ç›¸å…³ä¿¡æ¯......")
        fund_infos = get_fund_infos(fund_codes)

        logger.log("å°†åŸºé‡‘ç›¸å…³ä¿¡æ¯å†™å…¥ Excel æ–‡ä»¶......")
        write_to_xlsx(fund_infos, out_filename)

        # The emoji takes inspiration from the black (https://github.com/psf/black)
        logger.log("å®Œæ»¡ç»“æŸ! âœ¨ ğŸ° âœ¨")

    except Exception:
        logger.log("Oops! ç¨‹åºè¿è¡Œè¿‡ç¨‹ä¸­é‡åˆ°äº†é”™è¯¯ï¼Œæ‰“å°é”™è¯¯ä¿¡æ¯æ‘˜è¦å¦‚ä¸‹ï¼š")
        print_traceback_digest()

        with open(ERR_LOG_FILE, "w", encoding="utf-8") as f:
            traceback.print_exc(file=f)
        logger.log(f'è¯¦ç»†é”™è¯¯ä¿¡æ¯å·²å†™å…¥æ—¥å¿—æ–‡ä»¶ "{ERR_LOG_FILE}"ï¼Œè¯·å°†æ—¥å¿—æ–‡ä»¶æäº¤ç»™å¼€å‘è€…è¿›è¡Œè°ƒè¯• debug')


if __name__ == "__main__":
    main()  # pylint: disable=no-value-for-parameter
